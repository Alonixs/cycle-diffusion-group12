{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 12 Mini-project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create environment by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -f environment.yml\n",
    "!conda activate generative_prompt\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Install torch and torchvision (add to yml?)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Install taming-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd src/\n",
    "!git clone git@github.com:CompVis/taming-transformers.git\n",
    "%cd taming-transformers/\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO We have to remove WanDB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation data\n",
    "4 Prepare the AFHQ validation set for unpaired image-to-image translation (also for some images used by zero-shot image-to-image translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd cycle-diffusion/\n",
    "!git clone git@github.com:clovaai/stargan-v2.git\n",
    "%cd stargan-v2/\n",
    "!bash download.sh afhq-v2-dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained diffusion models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stable Diffusion\n",
    "\n",
    "#TODO Manually install pre-trained checkpoints: https://huggingface.co/CompVis/stable-diffusion-v-1-4-original\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Latent Diffusion Model\n",
    "\n",
    "#Do we need this?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. DDPM (AFHQ-Dog and FFHQ are from ILVR; CelebAHQ is from SDEdit; AFHQ-Cat and -Wild are trained by ourselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ckpts/\n",
    "!mkdir ddpm\n",
    "%cd ddpm/\n",
    "!wget https://image-editing-test-12345.s3-us-west-2.amazonaws.com/checkpoints/celeba_hq.ckpt\n",
    "!wget https://www.dropbox.com/s/g4h8sv07i3hj83d/ffhq_10m.pt\n",
    "!wget https://www.dropbox.com/s/u74w8vaw1f8lc4k/afhq_dog_4m.pt\n",
    "!wget https://www.dropbox.com/s/8i5aznjwdl3b5iq/cat_ema_0.9999_050000.pt\n",
    "!wget https://www.dropbox.com/s/tplximipy8zxaub/wild_ema_0.9999_050000.pt\n",
    "!wget https://www.dropbox.com/s/vqm6bxj0zslrjxv/configs.zip\n",
    "!unzip configs.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
