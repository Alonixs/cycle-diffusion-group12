#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=test
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=0:10:00
#SBATCH --mem=32000M
#SBATCH --output=output_test_rotations_%A.out

module purge
module load 2021
module load Anaconda3/2021.05

source activate generative_prompt


# TEST JOB
export CUDA_VISIBLE_DEVICES=0
export RUN_NAME=experiment_test2
export SEED=42
export LOCAL_RANK=0

# EXAMPLE COMMAND, with wandb disabled, and storing z's as: rotated_images_NR.npy/pickle
python -m torch.distributed.launch --nproc_per_node 1 --master_port 1446 main.py --seed $SEED --cfg experiments/$RUN_NAME.cfg --run_name $RUN_NAME$SEED --logging_strategy steps --logging_first_step true --logging_steps 4 --evaluation_strategy steps --eval_steps 50 --metric_for_best_model CLIPEnergy --greater_is_better false --save_strategy steps --save_steps 50 --save_total_limit 1 --load_best_model_at_end --gradient_accumulation_steps 4 --num_train_epochs 0 --adafactor false --learning_rate 1e-3 --do_eval --output_dir output/$RUN_NAME$SEED --overwrite_output_dir --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --eval_accumulation_steps 4 --ddp_find_unused_parameters true --verbose true --custom_z_name rotated_images --disable_wandb True --save_time_steps True


conda deactivate
